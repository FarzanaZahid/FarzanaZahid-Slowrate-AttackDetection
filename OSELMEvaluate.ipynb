{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "import traceback\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from os_elm import OS_ELM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# Instantiate os-elm\n",
    "# ===========================================\n",
    "def initialiseOSELM(n_input_nodes, n_hidden_nodes, n_output_nodes):\n",
    "    print(\"initialiseOSELM ===========================================\")\n",
    "    try:\n",
    "        os_elm = OS_ELM(\n",
    "            # the number of input nodes.\n",
    "            n_input_nodes=n_input_nodes,\n",
    "            # the number of output nodes.\n",
    "            n_output_nodes=n_output_nodes,\n",
    "            # the number of hidden nodes.\n",
    "            n_hidden_nodes=n_hidden_nodes,\n",
    "            \n",
    "            # activation function sigmoid applied to the hidden nodes only\n",
    "            activation='sigmoid',\n",
    "        )\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        raise e\n",
    "    return os_elm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************\n",
    "# Initialise Variables\n",
    "# ****************************************\n",
    "batch_size = 9\n",
    "start_data_limit = 0\n",
    "end_data_limit = batch_size\n",
    "n_input_nodes = 3\n",
    "n_hidden_nodes = 5\n",
    "n_output_nodes = 5\n",
    "n_classes = n_output_nodes\n",
    "os_elm = initialiseOSELM(n_input_nodes, n_hidden_nodes, n_output_nodes)\n",
    "x_classify_df = None\n",
    "x_classify = None\n",
    "evaluate_data = True\n",
    "load_data = True\n",
    "iteration = 1\n",
    "\n",
    "print('restoring model parameters...') \n",
    "os_elm.restore('./checkpoint/model.ckpt')\n",
    "\n",
    "while evaluate_data:\n",
    "    print(f\"start_data_limit : {start_data_limit}, end_data_limit : {end_data_limit}\")\n",
    "    # ===========================================\n",
    "    # Load dataset\n",
    "    # ===========================================\n",
    "    if load_data:\n",
    "        input_data = pd.read_csv(\"MultitestELM.csv\")\n",
    "                  \n",
    "                \n",
    "        pd.options.mode.chained_assignment = None\n",
    "        Fwd_Header_Len_col = input_data['Fwd_Header_Len']\n",
    "        Fwd_Header_Len_col.replace(to_replace = 0, value = Fwd_Header_Len_col.mean(), inplace=True)\n",
    "\n",
    "        Fwd_IAT_Max_col = input_data['Fwd_IAT_Max']\n",
    "        Fwd_IAT_Max_col.replace(to_replace = 0, value = Fwd_IAT_Max_col.mean(), inplace=True)\n",
    "\n",
    "        input_Data_length = len(input_data.index)\n",
    "        print(f'Total records to evaluate : {len(input_data.index)}')\n",
    "        load_data = False\n",
    "\n",
    "       \n",
    "        df0 = input_data[input_data['Label'] == 0]\n",
    "        print(f'Total records df0 : {len(df0.index)}')\n",
    "        df1 = input_data[input_data['Label'] == 1]\n",
    "        print(f'Total records df1 : {len(df1.index)}')\n",
    "        df2 = input_data[input_data['Label'] == 2]\n",
    "        print(f'Total records df2 : {len(df2.index)}')\n",
    "        df3 = input_data[input_data['Label'] == 3]\n",
    "        print(f'Total records df3 : {len(df3.index)}')\n",
    "        df4 = input_data[input_data['Label'] == 4]\n",
    "        print(f'Total records df4 : {len(df4.index)}')\n",
    "        \n",
    "        input_data = df0.append(df1, ignore_index=True).append(df2, ignore_index=True).append(df3, ignore_index=True).append(df4, ignore_index=True)\n",
    "    \n",
    "    x_classify_df_with_label = input_data[['Tot_Fwd_Pkts','Fwd_Header_Len','Fwd_IAT_Max', 'Label']]\n",
    "\n",
    "    x_classify_df = x_classify_df_with_label[['Tot_Fwd_Pkts','Fwd_Header_Len','Fwd_IAT_Max']]\n",
    "    print(f'Lenght of x_classify_df_with_label : {len(x_classify_df_with_label)} for iteration {iteration}')\n",
    "    iteration = iteration + 1\n",
    "    \n",
    "    x_classify=np.array(x_classify_df[start_data_limit:end_data_limit])\n",
    "    t_classify = x_classify_df_with_label['Label']\n",
    "    t_classify=np.array(t_classify[:len(x_classify)])\n",
    "    \n",
    "    # if True:\n",
    "    if end_data_limit > input_Data_length:\n",
    "        print(f\"end_data_limit : {end_data_limit}, input_Data_length : {input_Data_length}\")\n",
    "        evaluate_data = False\n",
    "\n",
    "    start_data_limit = end_data_limit\n",
    "    end_data_limit = end_data_limit + batch_size\n",
    "\n",
    "    # ===========================================\n",
    "    # Prepare dataset\n",
    "    # ===========================================\n",
    "    # shuffle dataset\n",
    "    perm = np.random.permutation(len(x_classify))\n",
    "    x_classify = x_classify[perm]\n",
    "    t_classify = t_classify[perm]\n",
    "    \n",
    "    # min_max_scalar = MinMaxScaler().fit(x_classify)\n",
    "    x_classifytest_normalised = MinMaxScaler().fit_transform(x_classify)\n",
    "    t_classifytest_categorised = to_categorical(t_classify, num_classes=n_classes)\n",
    "\n",
    "    print(f'x_train_normalised sahpe : {x_classifytest_normalised.shape}')\n",
    "    print(f't_test_categorised sahpe : {t_classifytest_categorised.shape}')\n",
    "\n",
    "    # ===========================================\n",
    "    # ReEvaluation\n",
    "    # ===========================================\n",
    "\n",
    "    [precision, accuracy, score, recall] = os_elm.evaluate(x_classifytest_normalised, t_classifytest_categorised, metrics=['accuracy', 'precision', 'score', 'recall'])\n",
    "    print(f'precision: {precision} , accuracy: {accuracy}, score: {score}, recall: {recall}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
